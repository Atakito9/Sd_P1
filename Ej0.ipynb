{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b2a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total registros válidos: 1568\n",
      "Fecha\t\tTemp_Max\n",
      "--- Máximos por día ---\n",
      "Fecha: 2-01-0,0, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-02-0,0, Muni: 106, Est: 1, Precip: 0\n",
      "Fecha: 2-02-0,2, Muni: 14, Est: 2, Precip: 0\n",
      "Fecha: 2-02-0,3, Muni: 120, Est: 1, Precip: 0\n",
      "Fecha: 2-02-0,4, Muni: 123, Est: 2, Precip: 0\n",
      "Fecha: 2-02-0,7, Muni: 6, Est: 4, Precip: 0\n",
      "Fecha: 2-02-0,8, Muni: 134, Est: 2, Precip: 0\n",
      "Fecha: 2-02-1,0, Muni: 16, Est: 1, Precip: 0\n",
      "Fecha: 2-02-1,1, Muni: 80, Est: 3, Precip: 0\n",
      "Fecha: 2-02-1,2, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-02-1,8, Muni: 133, Est: 2, Precip: 0\n",
      "Fecha: 2-02-2,2, Muni: 127, Est: 4, Precip: 0\n",
      "Fecha: 2-02-3,0, Muni: 115, Est: 3, Precip: 0\n",
      "Fecha: 2-03-0,0, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-03-0,1, Muni: 120, Est: 1, Precip: 0\n",
      "Fecha: 2-03-0,2, Muni: 123, Est: 2, Precip: 0\n",
      "Fecha: 2-03-0,4, Muni: 133, Est: 2, Precip: 0\n",
      "Fecha: 2-03-1,0, Muni: 127, Est: 4, Precip: 0\n",
      "Fecha: 2-04-0,6, Muni: 45, Est: 2, Precip: 0\n",
      "Fecha: 2-04-0,7, Muni: 16, Est: 1, Precip: 0\n",
      "Fecha: 2-04-0,8, Muni: 106, Est: 1, Precip: 0\n",
      "Fecha: 2-04-0,9, Muni: 7, Est: 4, Precip: 0\n",
      "Fecha: 2-04-1,0, Muni: 180, Est: 1, Precip: 0\n",
      "Fecha: 2-04-1,2, Muni: 13, Est: 2, Precip: 0\n",
      "Fecha: 2-04-1,3, Muni: 134, Est: 2, Precip: 0\n",
      "Fecha: 2-04-1,4, Muni: 133, Est: 2, Precip: 0\n",
      "Fecha: 2-04-1,5, Muni: 161, Est: 1, Precip: 0\n",
      "Fecha: 2-04-1,6, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-04-1,8, Muni: 123, Est: 2, Precip: 0\n",
      "Fecha: 2-04-2,0, Muni: 47, Est: 2, Precip: 0\n",
      "Fecha: 2-04-2,4, Muni: 49, Est: 3, Precip: 0\n",
      "Fecha: 2-04-3,8, Muni: 115, Est: 3, Precip: 0\n",
      "Fecha: 2-04-4,8, Muni: 127, Est: 4, Precip: 0\n",
      "Fecha: 2-05-0,0, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-05-0,2, Muni: 133, Est: 2, Precip: 0\n",
      "Fecha: 2-05-0,3, Muni: 106, Est: 1, Precip: 0\n",
      "Fecha: 2-05-0,4, Muni: 14, Est: 2, Precip: 0\n",
      "Fecha: 2-05-1,0, Muni: 161, Est: 1, Precip: 0\n",
      "Fecha: 2-05-1,6, Muni: 13, Est: 2, Precip: 0\n",
      "Fecha: 2-06-0,0, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-06-0,2, Muni: 120, Est: 1, Precip: 0\n",
      "Fecha: 2-07-0,0, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-07-0,1, Muni: 67, Est: 1, Precip: 0\n",
      "Fecha: 2-08-0,0, Muni: 106, Est: 1, Precip: 0\n",
      "Fecha: 2-08-0,1, Muni: 134, Est: 2, Precip: 0\n",
      "Fecha: 2-08-0,2, Muni: 123, Est: 2, Precip: 0\n",
      "Fecha: 2-08-0,3, Muni: 16, Est: 1, Precip: 0\n",
      "Fecha: 2-08-0,4, Muni: 6, Est: 4, Precip: 0\n",
      "Fecha: 2-08-0,6, Muni: 120, Est: 1, Precip: 0\n",
      "Fecha: 2-08-0,7, Muni: 115, Est: 3, Precip: 0\n",
      "Fecha: 2-08-0,8, Muni: 102, Est: 1, Precip: 0\n",
      "Fecha: 2-08-1,0, Muni: 161, Est: 1, Precip: 0\n",
      "Fecha: 2-08-1,2, Muni: 47, Est: 2, Precip: 0\n",
      "Fecha: 2-08-1,8, Muni: 67, Est: 1, Precip: 0\n",
      "Fecha: 2-08-2,1, Muni: 127, Est: 4, Precip: 0\n",
      "\n",
      "--- Máximo Absoluto ---\n",
      "Fecha: 2-01-0,0\n",
      "Municipio: 102, Estación: 1\n",
      "Precipitación Total: 0\n",
      "--- Comparativa (Porcentaje) ---\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# Inicialización del Contexto (si no estás en la shell interactiva)\n",
    "sc = SparkContext(\"local[*]\", \"Sd_P1\")\n",
    "file_name = \"calidad_aire_datos_meteo_mes.csv\"\n",
    "\n",
    "# Constantes Simbólicas del Dominio\n",
    "MAG_TEMP = 83  # Magnitud Temperatura \n",
    "MAG_PREC = 89  # Magnitud Precipitación \n",
    "FLAG_VALID = 'V' # Bandera de validación [cite: 81]\n",
    "\n",
    "# Carga del archivo (Asumiendo que lo subiste a Jupyter)\n",
    "raw_rdd = sc.textFile(f\"file:///home/jovyan/Sd_P1/{file_name}\")\n",
    "\n",
    "# Función para limpiar y estructurar una línea del CSV\n",
    "def parse_line(line):\n",
    "    try:\n",
    "        parts = line.split(';')\n",
    "        \n",
    "        # 1. Filtro de integridad básica\n",
    "        # Si la línea no tiene ni siquiera los metadatos básicos, la ignoramos.\n",
    "        if len(parts) < 9: \n",
    "            return None\n",
    "        \n",
    "        # Extracción de metadatos\n",
    "        municipio = parts[1]\n",
    "        estacion = parts[2]\n",
    "        magnitud = int(parts[3])\n",
    "        \n",
    "        # Construcción de Fecha\n",
    "        ano = parts[6]\n",
    "        mes = parts[7]\n",
    "        dia = parts[8]\n",
    "        fecha = f\"{ano}-{mes.zfill(2)}-{dia.zfill(2)}\"\n",
    "        \n",
    "        valores_validos = []\n",
    "        \n",
    "        # 2. Iteración segura\n",
    "        base_idx = 9\n",
    "        for i in range(24):\n",
    "            val_idx = base_idx + (i * 2)\n",
    "            flag_idx = base_idx + (i * 2) + 1\n",
    "            \n",
    "            # CRÍTICO: Verificamos que el índice del flag (que es el mayor)\n",
    "            # esté dentro de los límites de la lista 'parts'.\n",
    "            if flag_idx >= len(parts): \n",
    "                break\n",
    "            \n",
    "            val_str = parts[val_idx]\n",
    "            flag = parts[flag_idx]\n",
    "            \n",
    "            if flag == 'V':\n",
    "                # Conversión segura a float\n",
    "                valor = float(val_str.replace(',', '.'))\n",
    "                valores_validos.append(valor)\n",
    "                \n",
    "        return {\n",
    "            'fecha': fecha,\n",
    "            'muni': municipio,\n",
    "            'est': estacion,\n",
    "            'mag': magnitud,\n",
    "            'vals': valores_validos\n",
    "        }\n",
    "    except Exception:\n",
    "        # Si cualquier cosa falla en esta línea específica (formato, índices, conversión),\n",
    "        # devolvemos None para que el filtro posterior la elimine limpiamente\n",
    "        # sin abortar el trabajo de Spark.\n",
    "        return None\n",
    "\n",
    "# --- RECARGA DEL RDD CON LA NUEVA FUNCIÓN ---\n",
    "\n",
    "# Asegúrate de volver a ejecutar la creación del RDD filtrado\n",
    "data_rdd = raw_rdd.map(parse_line).filter(lambda x: x is not None)\n",
    "\n",
    "temp_rdd = data_rdd.filter(lambda x: x['mag'] == MAG_TEMP)\n",
    "\n",
    "# Prueba de nuevo el conteo\n",
    "print(f\"Total registros válidos: {data_rdd.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Ejercicio 2\n",
    "# 1. Mapeamos a (Fecha, Max_Temperatura_Del_Registro)\n",
    "# Usamos max(x['vals']) porque la lista ya está filtrada y convertida a float\n",
    "# Filtramos primero para asegurar que 'vals' no esté vacío y evitar errores\n",
    "daily_max_rdd = temp_rdd.filter(lambda x: len(x['vals']) > 0) \\\n",
    "                        .map(lambda x: (x['fecha'], max(x['vals'])))\n",
    "\n",
    "# Nota: Si hay múltiples estaciones midiendo el mismo día y quieres \n",
    "# EL MÁXIMO de la Comunidad ese día, hacemos una reducción:\n",
    "final_daily_max = daily_max_rdd.reduceByKey(lambda a, b: max(a, b)).sortByKey()\n",
    "\n",
    "# Salida\n",
    "print(\"Fecha\\t\\tTemp_Max\")\n",
    "for date, t_max in final_daily_max.collect():\n",
    "    print(f\"{date}\\t{t_max}\")\n",
    "\n",
    "\n",
    "#Ejercicio 3\n",
    "# 1. Filtramos por Precipitación y calculamos la suma diaria por estación\n",
    "precip_rdd = data_rdd.filter(lambda x: x['mag'] == MAG_PREC) \\\n",
    "                     .map(lambda x: (\n",
    "                         x['fecha'], \n",
    "                         (x['muni'], x['est'], sum(x['vals'])) # Payload\n",
    "                     ))\n",
    "\n",
    "# PARTE A: Máximo por día\n",
    "# ReduceByKey: Comparamos dos estaciones del mismo día y nos quedamos con la de mayor lluvia\n",
    "# x e y son tuplas (muni, est, total). Comparamos x[2] con y[2]\n",
    "max_precip_por_dia = precip_rdd.reduceByKey(lambda x, y: x if x[2] >= y[2] else y) \\\n",
    "                               .sortByKey()\n",
    "\n",
    "print(\"--- Máximos por día ---\")\n",
    "# Output: Fecha, Muni, Est, Total [cite: 90]\n",
    "for date, data in max_precip_por_dia.collect():\n",
    "    print(f\"Fecha: {date}, Muni: {data[0]}, Est: {data[1]}, Precip: {data[2]}\")\n",
    "\n",
    "# PARTE B: Máximo Absoluto del periodo [cite: 91]\n",
    "# Buscamos en el RDD el registro con el valor [2] (total) más alto\n",
    "# Usamos una función key para indicarle a max() qué valor comparar\n",
    "max_absoluto = max_precip_por_dia.max(key=lambda x: x[1][2])\n",
    "\n",
    "print(\"\\n--- Máximo Absoluto ---\")\n",
    "print(f\"Fecha: {max_absoluto[0]}\")\n",
    "print(f\"Municipio: {max_absoluto[1][0]}, Estación: {max_absoluto[1][1]}\")\n",
    "print(f\"Precipitación Total: {max_absoluto[1][2]}\")\n",
    "\n",
    "# Ejercicio 4\n",
    "def get_daily_avg(record):\n",
    "    if len(record['vals']) == 0: return None\n",
    "    avg = sum(record['vals']) / len(record['vals'])\n",
    "    return (record['fecha'], avg)\n",
    "\n",
    "# 1. Creamos RDDs separados para cada estación específica [cite: 96]\n",
    "# Referencia: Municipio 6, Estación 4\n",
    "ref_station = temp_rdd.filter(lambda x: int(x['muni']) == 6 and int(x['est']) == 4) \\\n",
    "                      .map(get_daily_avg) \\\n",
    "                      .filter(lambda x: x is not None)\n",
    "\n",
    "# Comparada: Municipio 5, Estación 2\n",
    "comp_station = temp_rdd.filter(lambda x: int(x['muni']) == 5 and int(x['est']) == 2) \\\n",
    "                       .map(get_daily_avg) \\\n",
    "                       .filter(lambda x: x is not None)\n",
    "\n",
    "# 2. Unimos los datos por Fecha (Inner Join)\n",
    "# Resultado estructura: (Fecha, (Media_Ref, Media_Comp))\n",
    "joined_data = ref_station.join(comp_station)\n",
    "\n",
    "# 3. Calculamos el porcentaje\n",
    "# (Fecha, (Ref, Comp)) -> (Fecha, Porcentaje)\n",
    "percentage_rdd = joined_data.mapValues(lambda x: (x[1] / x[0]) * 100).sortByKey()\n",
    "\n",
    "print(\"--- Comparativa (Porcentaje) ---\")\n",
    "for date, pct in percentage_rdd.collect():\n",
    "    print(f\"Fecha: {date}, Porcentaje: {percentage_rdd:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
